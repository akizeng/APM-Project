{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the \"../input/\" directory.\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input/fastai-pretrained\"))\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir -p /tmp/.cache/torch/checkpoints/\n!cp ../input/fastai-pretrained/densenet161-8d451a50.pth /tmp/.cache/torch/checkpoints/densenet161-8d451a50.pth\n!cp ../input/fastai-pretrained/densenet169-b2777c0a.pth /tmp/.cache/torch/checkpoints/densenet169-b2777c0a.pth","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mplimg\nfrom matplotlib.pyplot import imshow\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader,Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport time \nimport tqdm\nfrom PIL import Image\ntrain_on_gpu = True\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n\nimport warnings\nwarnings.simplefilter(\"ignore\", category=DeprecationWarning)\n\nfrom collections import OrderedDict\nimport cv2\n\nimport keras\nfrom keras.models import Model\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Input, Activation, Dropout, GlobalAveragePooling2D, \\\n    BatchNormalization, concatenate, AveragePooling2D\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\n\nfrom keras import layers\nfrom keras.preprocessing import image\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout\nfrom keras.models import Model\n\nimport keras.backend as K\nfrom keras.models import Sequential\n\nimport warnings\nwarnings.simplefilter(\"ignore\", category=DeprecationWarning)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision.models import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading...\nfrom fastai import *\nfrom fastai.vision import *\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport scipy as sp\nfrom functools import partial\nfrom sklearn import metrics\nfrom collections import Counter\nfrom fastai.callbacks import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Making pretrained weights work without needing to find the default filename\nif not os.path.exists('/tmp/.cache/torch/checkpoints/'):\n        os.makedirs('/tmp/.cache/torch/checkpoints/')\n!cp '../input/fastai-pretrained/densenet201/densenet201-4c113574.pth' '/tmp/.cache/torch/checkpoints/densenet201-c1103571.pth'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Make sure cudnn is enabled:', torch.backends.cudnn.enabled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set seed fol all\ndef seed_everything(seed=1358):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading train_dataset\nbase_image_dir = os.path.join('..', 'input/humpback-whale-identification/')\nbase_image_dir2 = os.path.join('..', 'input/new_train_whale/')\ntrain_dir = os.path.join(base_image_dir2,'new_train/')\ndf = pd.read_csv(os.path.join(base_image_dir, 'train.csv'))\ndf['path'] = df['Id'].map(lambda x: os.path.join(train_dir,'{}.png'.format(x)))\ndf = df.drop(columns=['Id'])\ndf = df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN =\"../input/humpback-whale-identification/train\"\nTEST = \"../input/humpback-whale-identification/test\"\nLABELS = \"../input/humpback-whale-identification/train.csv\"\nSUB = \"../input/humpback-whale-identification/sample_submission.csv\"\n\ndef text2number(LABELS):\n    df = pd.read_csv(LABELS)\n    \n    uni_labels = pd.DataFrame(df['Id'].unique(),columns=['Id'])\n    uni_labels.index.name = 'ID_new'\n    uni_labels = uni_labels.reset_index()\n\n\n    df = df.merge(uni_labels,on='Id')\n    \n    return df\n    \n#submit = [p for _, p, _ in pd.read_csv(SUB).to_records()]\n#join = list(tagged.keys()) + submit\ndf = text2number(LABELS)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tagged = dict([(p, w) for _, p,_, w in df.to_records()])\n# tagged.items()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find fluke pics of whales that have less than 5 pics in training data\n\nTRAIN =\"../input/humpback-whale-identification/train\"\nTEST = \"../input/humpback-whale-identification/test\"\nLABELS = \"../input/humpback-whale-identification/train.csv\"\nSUB = \"../input/humpback-whale-identification/sample_submission.csv\"\n\ntrain = pd.read_csv(LABELS)\ntrain_count = train.groupby('Id').count().rename(columns={\"Image\":\"image_count\"})\ntrain = train.merge(train_count,on=['Id'])\nfilelist = train['Image'].loc[(train['image_count']>10)].tolist()\nfilelist[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import numpy as np\n# from scipy import misc, ndimage\n# import keras\n# from keras import backend as k\n# from keras.preprocessing.image import ImageDataGenerator\n# import matplotlib.image as mpimg\n# from time import time\n# import tqdm \n\n# path = \"../input/humpback-whale-identification/train\"       \n# gen = ImageDataGenerator(rotation_range=20, \n#                          width_shift_range= 0.1, \n#                          height_shift_range = 0.1)\n\n# tagged_new = tagged.copy() \n\n# t = time()          \n# for img in tqdm(filelist):\n#     try:\n#         class_num = tagged[img]\n#         image = np.expand_dims(mpimg.imread(os.path.join(path,img)),0)  \n#         aug_iter = gen.flow(image)\n#         aug_images = [next(aug_iter)[0].astype(np.uint8) for i in range(5)]\n#         aug_image_names = [str(i)+\"_\"+img for i in range(5)]\n#         for i in range(5):\n#             plt.imsave(os.path.join(path,aug_image_names[i]),aug_images[i])\n#             tagged_new[aug_image_names[i]] = class_num\n#     except:\n#         pass\n# print(time()-t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# len(tagged_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set Batch Size and Image size\nbs = 32 \nsz=100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# value = {}\n# count = 0\n# for whale in df['p.unique():\n#     value[whale] = count\n#     count += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filelist[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['keep'] = df['Id']\n\ndef keep(data):\n    if data in filelist:\n        return 1\n    else:\n        return 0\n    \ndf['keep'] = df['Image'].map(keep)\ndf['keep'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_5 = df[df['keep'] == 1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_small = df_5[2500:5000]\ndf_new_whale = df_5[df_5['Id'] == 'new_whale']\ndf_not_new = df_5[df_5['Id'] != 'new_whale']\nprint(len(df_new_whale), len(df_not_new))\n\ndf_1 = df_new_whale[:500]\ndf_2 = df_not_new[:2000]\ndf_training = df_1.append(df_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1['Image'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# run this chunk only when augmented data is used\ndf_new = pd.DataFrame({'Image':list(tagged_new.keys()),\n                       'ID_new':list(tagged_new.values())})\ndf_new = df_new.merge(df[['ID_new','Id']].drop_duplicates(),how='left',on='ID_new')\nprint(len(df_new))\ndf_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = Path('../input/humpback-whale-identification/')\nPATH2 = Path('../input/new_train_whale/')\n\ndf_train = pd.read_csv(PATH/'train.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = ImageDataBunch.from_df(df=df_training,\n                              path=PATH, folder='train', \n                              valid_pct=0.1,\n                              ds_tfms=get_transforms(flip_vert=True, max_warp=0.1, max_zoom=1.15, max_rotate=45.),\n                              size=224,\n                              bs=50, \n                              num_workers=os.cpu_count()\n                             ).normalize(imagenet_stats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Classes: {data.classes}')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(rows=3, figsize=(7,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making pretrained weights work without needing to find the default filename\nif not os.path.exists('/tmp/.cache/torch/checkpoints/'):\n        os.makedirs('/tmp/.cache/torch/checkpoints/')\n!cp '../input/fastai-pretrained/resnet50-19c8e357.pth' '/tmp/.cache/torch/checkpoints/resnet50-19c8e357.pth'\n!cp '../input/fastai-pretrained/densenet161-8d451a50.pth' '/tmp/.cache/torch/checkpoints/densenet161-8d451a50.pth'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp '../input/fastai-pretrained/densenet201-c1103571.pth' '/tmp/.cache/torch/checkpoints/densenet201-c1103571.pth'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PATH = \"../input/aptos2019-blindness-detection\"\n!mkdir -p /tmp/.cache/torch/checkpoints/\n!cp ../input/fastai-pretrained/densenet161-8d451a50.pth /tmp/.cache/torch/checkpoints/densenet161-8d451a50.pth\n!cp ../input/fastai-pretrained/densenet169-b2777c0a.pth /tmp/.cache/torch/checkpoints/densenet169-b2777c0a.pth\n!cp ../input/fastai-pretrained/densenet169-b2777c0a.pth /tmp/.cache/torch/checkpoints/densenet169-b2777c0a.pth\n!cp ../input/fastai-pretrained/densenet201-c1103571.pth /tmp/.cache/torch/checkpoints/densenet201-c1103571.pth\n# densenet201-c1103571.pth\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_1 = cnn_learner(data, models.densenet201, metrics=[accuracy], pretrained=True).mixup()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_1.fit_one_cycle(10,1e-02)\nlearn_1.recorder.plot_losses()\nlearn_1.recorder.plot_metrics()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_1.unfreeze()\nlearn_1.fit_one_cycle(4, slice(5e-6, 0.001/5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn_2.fit_one_cycle(10,1e-02)\nlearn_1.recorder.plot_losses()\nlearn_1.recorder.plot_metrics()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_1.freeze()\nlearn_1.fit_one_cycle(4, slice(5e-6, 0.001/5))\nlearn_1.recorder.plot_losses()\nlearn_1.recorder.plot_metrics()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_1.unfreeze()\nlearn_1.fit_one_cycle(4, slice(5e-6, 0.001/5))\nlearn_1.recorder.plot_losses()\nlearn_1.recorder.plot_metrics()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_1.model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_1.validate(metrics=[accuracy])\n# learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_1.validate.plot_metrics()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}